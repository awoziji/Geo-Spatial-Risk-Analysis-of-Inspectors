{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('chained_assignment', None)\n",
    "ds = pd.read_csv(\"S:...//inspector _list.csv\")\n",
    "ds = ds.rename(columns={'ELEVATOR Employee': 'Name'})\n",
    "\n",
    "ds[\"Name\"] = ds[\"Name\"].str.replace('[^\\x00-\\x7F]','')\n",
    "ds[\"Name\"] = ds[\"Name\"].map(str.upper)\n",
    "ds[\"Name\"] = ds[\"Name\"].map(str.strip)\n",
    "\n",
    "\n",
    "#ACCELLA data\n",
    "df = pd.read_csv(\"..\\\\Inspector Spatial Analysis Oct 16 - 22.csv\")\n",
    "\n",
    "df = df[[\"INSPECTOR_NAME_FML#\", \"DATE_INSPECTION\", \"MILEAGE_START\", \"MILEAGE_END\", \"DATE_SCHEDULED\", \"STATUS\", \"INSPECTOR_DEPT\", \\\n",
    "         \"HOUSE#\", \"STREET_NAME\", \"LONGITUDE\", \"LATITUDE\", \"CITY\"]]\n",
    "\n",
    "df = df.rename(columns={'INSPECTOR_NAME_FML#': 'NAME'})\n",
    "\n",
    "df[\"ADDRESS\"] = df[\"HOUSE#\"] + \" \" + df[\"STREET_NAME\"] + \" \" + df[\"CITY\"]\n",
    "\n",
    "df[\"ADDRESS\"] = df[\"ADDRESS\"].astype(str)\n",
    "df[\"ADDRESS\"] = df[\"ADDRESS\"].map(str.upper)\n",
    "df[\"NAME\"] = df[\"NAME\"].astype(str)\n",
    "df[\"NAME\"] = df[\"NAME\"].map(str.upper)\n",
    "df[\"NAME\"] = df[\"NAME\"].map(str.strip)\n",
    "df[\"NAME\"] = df[\"NAME\"].str.replace('[^\\x00-\\x7F]','')\n",
    "df = df[df[\"NAME\"] != \"NAN\"]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['DATE_SCHEDULED'] = pd.to_datetime(df['DATE_SCHEDULED'])\n",
    "\n",
    "print len(df)\n",
    "\n",
    "#get week date time of interest:\n",
    "\n",
    "#start_time = str(lv[\"Start Time\"][i].month) + '-' + str(lv[\"Start Time\"][i].day) + '-' + str(lv[\"Start Time\"][i].year)\n",
    "#end_time = str(lv[\"End Time\"][i].month) + '-' + str(lv[\"End Time\"][i].day) + '-' + str(lv[\"End Time\"][i].year)\n",
    "\n",
    "start_time = '10-17-2016'\n",
    "end_time = '10-21-2016'\n",
    "\n",
    "mask = (df['DATE_SCHEDULED'] >= start_time) & (df['DATE_SCHEDULED'] <= end_time)\n",
    "\n",
    "#mask = (df['DATE_SCHEDULED'] >= start_time)\n",
    "df = df.loc[mask]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#print len(df)\n",
    "\n",
    "#mask = df['DATE_SCHEDULED'] <= end_time\n",
    "#df = df.loc[mask]\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Field Force Management \n",
    "\n",
    "\n",
    "dfm = pd.read_csv(\"..\\\\Worker_Stops_Time_Oct2016_EDIT.csv\")\n",
    "\n",
    "dfm = dfm[[\"Group\", \"Name\",\"Start Time\", \"Departure Time\", \"Event Type\",\"Event Name\", \"Address\", \"Stop Duration\", \"GPS Distance\", \\\n",
    "             \"Travel Duration\", \"Lat\", \"Lon\"]]\n",
    "\n",
    "\n",
    "#print \"length of concate\", len(dfm)\n",
    "\n",
    "dfm['Name'] = dfm['Name'].map(lambda x: x.strip('0123456789'))\n",
    "dfm[\"Name\"] = dfm[\"Name\"].map(str.strip)\n",
    "dfm[\"Name\"] = dfm[\"Name\"].str.replace('[^\\x00-\\x7F]','')\n",
    "\n",
    "dfm['Start Time'] = pd.to_datetime(dfm['Start Time'])\n",
    "\n",
    "\n",
    "start_time = '10-17-2016'\n",
    "end_time = '10-21-2016'\n",
    "\n",
    "mask = (dfm['Start Time'] >= start_time) & (dfm['Start Time'] <= end_time)\n",
    "\n",
    "dfm = dfm.loc[mask]\n",
    "\n",
    "dfm = dfm.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1b: Create List of Inspectors from Accela to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the list of supervisor names and create new dataframe from accela output with those names\n",
    "names = []\n",
    "for i in range(0, len(ds)):\n",
    "    names.append(ds[\"Name\"][i])\n",
    "\n",
    "names = set(names)\n",
    "names = list(names)\n",
    "names = sorted(names)\n",
    "print \"name list\"\n",
    "print names\n",
    "\n",
    "df2 = pd.DataFrame(columns=(\"NAME\",\"DATE_INSPECTION\", \"MILEAGE_START\", \"MILEAGE_END\", \"DATE_SCHEDULED\", \"STATUS\", \\\n",
    "                            \"INSPECTOR_DEPT\", \"HOUSE#\", \"STREET_NAME\", \"LONGITUDE\", \"LATITUDE\", \"CITY\",\"ADDRESS\"))\n",
    "\n",
    "#get the names in accela\n",
    "for i in range(0, len(df)):\n",
    "    if df[\"NAME\"][i] in names:\n",
    "        #print df[\"NAME\"][i]\n",
    "        df2.loc[i] = [df[\"NAME\"][i],df[\"DATE_INSPECTION\"][i], df[\"MILEAGE_START\"][i], df[\"MILEAGE_START\"][i], \\\n",
    "                     df[\"DATE_SCHEDULED\"][i],df[\"STATUS\"][i], df[\"INSPECTOR_DEPT\"][i], df[\"HOUSE#\"][i], \\\n",
    "                     df[\"STREET_NAME\"][i],df[\"LONGITUDE\"][i], df[\"LATITUDE\"][i], df[\"CITY\"][i], df[\"ADDRESS\"][i]  ]   \n",
    "\n",
    "\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1c: Create List of Inspectors in FFM dataset to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ffm_accela_names = []\n",
    "\n",
    "for i in range(0, len(dfm)):\n",
    "    ffm_accela_names.append(dfm[\"Name\"][i])\n",
    "        \n",
    "ffm_accela_names = set(ffm_accela_names)\n",
    "ffm_accela_names = list(ffm_accela_names)\n",
    "ffm_accela_names = sorted(ffm_accela_names)\n",
    "#print ffm_accela_names\n",
    "#print len(ffm_accela_names)\n",
    "\n",
    "dfm2 = pd.DataFrame(columns=(\"Name\",\"Start Time\", \"Departure Time\", \"Event Type\", \"Event Name\", \"Address\", \\\n",
    "                            \"Stop Duration\", \"GPS Distance\", \"Travel Duration\", \"Lat\", \"Lon\"))\n",
    "\n",
    "#get the names in accela\n",
    "for i in range(0, len(dfm)):\n",
    "    if dfm[\"Name\"][i] in names:\n",
    "        #print df[\"NAME\"][i]\n",
    "        dfm2.loc[i] = [dfm[\"Name\"][i],dfm[\"Start Time\"][i], dfm[\"Departure Time\"][i], dfm[\"Event Type\"][i], \\\n",
    "                     dfm[\"Event Name\"][i],dfm[\"Address\"][i], dfm[\"Stop Duration\"][i], dfm[\"GPS Distance\"][i], \\\n",
    "                     dfm[\"Travel Duration\"][i],dfm[\"Lat\"][i], dfm[\"Lon\"][i]]   \n",
    "\n",
    "\n",
    "dfm2 = dfm2.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dfm2[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print names\n",
    "print len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Clean Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "#get rid of zip code in field force dataframe\n",
    "dfm2['Address'] = dfm2['Address'].astype(str)\n",
    "#dfm['Address'] = dfm['Address'].map(lambda x: x.strip('0123456789'))\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].map(str.strip)\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].map(str.upper)\n",
    "\n",
    "for i in range(0, len(dfm2)):\n",
    "    text = dfm2[\"Address\"][i]\n",
    "    #print \"original text:\", text\n",
    "    #remove last element in string\n",
    "    text = text.rsplit(' ', 1)[0]\n",
    "    #print \"split text:\", text\n",
    "    #print\n",
    "    dfm2[\"Address\"][i] = text\n",
    "\n",
    "    \n",
    "#further cleaning of field force\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].str.replace(',', '')\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].str.replace('NEW YORK NY', 'MANHATTAN')\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].str.replace('LONG ISLAND CITY', 'QUEENS')\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].str.replace('SUNNYSIDE', 'QUEENS')\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].str.replace('JAMAICA', 'QUEENS')\n",
    "dfm2[\"Address\"] = dfm2[\"Address\"].str.replace(' NY', '')\n",
    "#dfm2[\"Address\"] = dfm2[\"Address\"].str.replace('TH ', ' ')\n",
    "\n",
    "#clean accela data\n",
    "df2[\"ADDRESS\"] = df2[\"ADDRESS\"].map(str.strip)\n",
    "df2[\"ADDRESS\"] = df2[\"ADDRESS\"].map(str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Address Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from operator import itemgetter\n",
    "from difflib import SequenceMatcher as SM\n",
    "#s1 = '213'\n",
    "#s2 = '250'\n",
    "#print SM(None, s1, s2).ratio()\n",
    "\n",
    "df2[\"Visit\"] = \"NA\"\n",
    "df2[\"Closest Address Visited\"] = \"NA\"\n",
    "\n",
    "df2[\"Fuzzy Score\"] = 0.0\n",
    "\n",
    "for i in range(0, len(df2)):\n",
    "#for i in range(0, 10):\n",
    "    #df3 =df2[df2['NAME'] == names[i]]\n",
    "    #df3 = df3.reset_index(drop=True)\n",
    "    \n",
    "    #get name from accella data and subset ffm data\n",
    "    name = df2[\"NAME\"][i]\n",
    "    dfm3 = dfm2[dfm2[\"Name\"] == name]\n",
    "    dfm3 = dfm3.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    #print df3\n",
    "    #print\n",
    "    #print dfm2\n",
    "    \n",
    "    ratio_list = []\n",
    "    \n",
    "    for j in range(0, len(dfm3)):\n",
    "        if dfm3.empty:\n",
    "            print \"dfm3 empty\"\n",
    "            \n",
    "        \n",
    "        s1 = str(df2[\"ADDRESS\"][i])\n",
    "        s2 = str(dfm3[\"Address\"][j])\n",
    "        ratio =  SM(None, s1, s2).ratio()\n",
    "        ratio = round(ratio, 2)\n",
    "        \n",
    "        if dfm3[\"Address\"][j] != 'NAN':\n",
    "            ratio_list.append([dfm3[\"Address\"][j], ratio])\n",
    "        \n",
    "        if ratio >= 0.89:\n",
    "            df2[\"Visit\"][i] = \"YES\"\n",
    "        \n",
    "        elif (ratio < 0.89 and df2[\"Visit\"][i] == \"NA\"):\n",
    "            df2[\"Visit\"][i] = \"NO\"\n",
    "       \n",
    "        \n",
    "    #ratio_list =  sorted(ratio_list, reverse=True)\n",
    "    \n",
    "    ratio_list = sorted(ratio_list, key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    if df2[\"Visit\"][i] != \"NA\":\n",
    "        #print \n",
    "        print len(ratio_list)\n",
    "        \n",
    "        if len(ratio_list) != 0:\n",
    "            print ratio_list[0]\n",
    "            df2[\"Closest Address Visited\"][i] = ratio_list[0][0]\n",
    "            df2[\"Fuzzy Score\"][i] = ratio_list[0][1]\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Location Using Nearest Neighbor Lat/Lon Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    #convert into feet before returning\n",
    "    return km*3280.84\n",
    "\n",
    "\n",
    "\n",
    "#print haversine(lon1, lat1, lon2, lat2)\n",
    "\n",
    "df2[\"Visit Spatial\"] = \"NA\"\n",
    "df2[\"Closest Address Visited Spatial\"] = \"NA\"\n",
    "\n",
    "df2[\"Closest Distance (ft)\"] = 0.0\n",
    "\n",
    "for i in range(0, len(df2)):\n",
    "#for i in range(2, 4):\n",
    "\n",
    "    #get name from accella data and subset ffm data\n",
    "    name = df2[\"NAME\"][i]\n",
    "    dfm3 = dfm2[dfm2[\"Name\"] == name]\n",
    "    dfm3 = dfm3.reset_index(drop=True)\n",
    "    \n",
    "    #drop NANs\n",
    "    #dfm3 = dfm3.dropna()\n",
    "    dfm3 = dfm3.reset_index(drop=True)\n",
    "\n",
    "    #print dfm3\n",
    "    \n",
    "    lon1 = df2[\"LONGITUDE\"][i]\n",
    "    lat1 = df2[\"LATITUDE\"][i]\n",
    "    #print df3\n",
    "    #print\n",
    "    #print dfm2\n",
    "    \n",
    "    feet_list = []\n",
    "    \n",
    "    for j in range(0, len(dfm3)):\n",
    "        if dfm3.empty:\n",
    "            print \"dfm3 empty\"\n",
    "     \n",
    "        lon2 = dfm3[\"Lon\"][j]\n",
    "        lat2 = dfm3[\"Lat\"][j]\n",
    "\n",
    "        dist = haversine(lon1, lat1, lon2, lat2)\n",
    "        dist = round(dist)\n",
    "        \n",
    "        #only create list if have address, because cannot sort dist NANs properly\n",
    "        if dfm3[\"Address\"][j] != 'NAN':\n",
    "            feet_list.append([dfm3[\"Address\"][j], dist])\n",
    "\n",
    "        if dist <= 1000:\n",
    "            df2[\"Visit Spatial\"][i] = \"YES\"\n",
    "        \n",
    "        elif (dist > 1000 and df2[\"Visit Spatial\"][i] == \"NA\"):\n",
    "            df2[\"Visit Spatial\"][i] = \"NO\"\n",
    "       \n",
    "    #sort to get the minimum distance \n",
    "    feet_list =  sorted(feet_list, key=itemgetter(1), reverse=False)\n",
    "    #print feet_list\n",
    "    #print\n",
    "    \n",
    "    #ratio_list = sorted(ratio_list, key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    if df2[\"Visit Spatial\"][i] != \"NA\":\n",
    "        print feet_list[0]\n",
    "        df2[\"Closest Address Visited Spatial\"][i] = feet_list[0][0]\n",
    "        df2[\"Closest Distance (ft)\"][i] = feet_list[0][1]\n",
    "    \n",
    "    \"\"\"\n",
    "    if df2[\"Visit\"][i] != \"NA\":\n",
    "        print \n",
    "        print ratio_list[0]\n",
    "        df2[\"Closest Address Visited\"][i] = ratio_list[0][0]\n",
    "        df2[\"Fuzzy Score\"][i] = ratio_list[0][1]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2[df2[\"Closest Address Visited\"] != 'NA']\n",
    "\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.to_csv(\"S..\\Analysis 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
